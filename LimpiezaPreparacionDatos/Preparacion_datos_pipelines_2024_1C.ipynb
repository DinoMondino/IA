{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"W7DCl-tpDdV_","executionInfo":{"status":"ok","timestamp":1710777691305,"user_tz":180,"elapsed":3880,"user":{"displayName":"Diana Carolina VERTIZ DEL VALLE","userId":"04236681262725283456"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.impute import SimpleImputer"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"O_9oYsrySzl8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710777750228,"user_tz":180,"elapsed":58931,"user":{"displayName":"Diana Carolina VERTIZ DEL VALLE","userId":"04236681262725283456"}},"outputId":"b89a683f-ffb9-4ae0-e890-5249c2caf8eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Inteligencia Artificial/IA - Clases de Práctica/ContenidosPorTemas\n","google.colab\n"]}],"source":["import sys\n","if 'google.colab' in sys.modules:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    %cd '/content/drive/MyDrive/Inteligencia Artificial/IA - Clases de Práctica/ContenidosPorTemas'\n","    print('google.colab')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HBZOtUddDdWA"},"outputs":[],"source":["np.random.seed(42)\n","\n","# Cargamos los datos\n","df_housing = pd.read_csv(\"./1_datos/housing.csv\")\n","\n","# Creamos nuestro atributo categórico para los ingresos\n","df_housing[\"income_cat\"] = pd.cut(df_housing[\"median_income\"], bins=[0., 1.5, 3.0, 4.5, 6., np.inf], labels=[1, 2, 3, 4, 5])\n","\n","# Dividimos los datos en conjunto de entrenamiento y prueba\n","strat_train_set, strat_test_set = train_test_split(df_housing, test_size=0.2, stratify=df_housing[\"income_cat\"], random_state=42)\n","\n","# Eliminamos la categoria income_cat de ambos conjuntos porque no la usamos\n","for set_ in (strat_train_set, strat_test_set):\n","    set_.drop(\"income_cat\", axis=1, inplace=True)\n","\n","# Separamos predictores y etiquetas\n","housing = strat_train_set.drop(\"median_house_value\", axis=1)\n","housing_labels = strat_train_set[\"median_house_value\"].copy()"]},{"cell_type":"markdown","metadata":{"id":"vosc6MGvDdWA"},"source":["# Prepación de los Datos usando transformers\n","\n","implementar funciones para la transformación de los datos es muy útil.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2AJHaE4zDdWB"},"outputs":[],"source":["from sklearn.preprocessing import FunctionTransformer\n","\n","log_transformer = FunctionTransformer(np.log, inverse_func=np.exp)\n","log_pop = log_transformer.transform(housing[[\"population\"]])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pZQpec-oDdWB"},"outputs":[],"source":["fig, axs = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n","\n","housing[\"population\"].hist(ax=axs[0], bins=50)\n","log_pop.hist(ax=axs[1], bins=50)\n","\n","axs[0].set_xlabel(\"Population\")\n","axs[1].set_xlabel(\"Log of population\")\n","axs[0].set_ylabel(\"Number of districts\")\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"kLfVZKzdDdWC"},"source":["Pero ¿qué sucede si deseas que tu transformador sea entrenable, es decir, que aprenda algunos parámetros en el método `fit()` y los use más tarde en el método `transform()`? Para esto, necesitas escribir una clase personalizada. Scikit-Learn se basa en duck typing, por lo que esta clase no tiene que heredar de ninguna clase base en particular. Lo único que necesita son tres métodos: `fit()` (que debe devolver `self`), `transform()` y `fit_transform()`."]},{"cell_type":"markdown","metadata":{"id":"9fd4JxqGDdWC"},"source":["Se puede tener el método `fit_transform()` simplemente agregando `TransformerMixin` como una clase base: la implementación predeterminada simplemente llamará a `fit()` y luego a `transform()`. Si agregas `BaseEstimator` como una clase base, también obtendrás dos métodos adicionales: `get_params()` y `set_params()`. Estos serán útiles para ajustar hiperparámetros."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HBu47GIrDdWC"},"outputs":[],"source":["from sklearn.base import BaseEstimator, TransformerMixin\n","from sklearn.utils.validation import check_array, check_is_fitted\n","\n","class StandardScalerClone(BaseEstimator, TransformerMixin):\n","    def __init__(self, with_mean=True):\n","        self.with_mean = with_mean\n","\n","    def fit(self, X, y=None):  # y es requerido aunque no se usa\n","        X = check_array(X)  # verifica que X es un array con valores flotantes finitos\n","        self.mean_ = X.mean(axis=0)\n","        self.scale_ = X.std(axis=0)\n","        self.n_features_in_ = X.shape[1]  # esta información se guarda en fit\n","        return self  # siempre debe retornar self!\n","\n","    def transform(self, X):\n","        check_is_fitted(self)  # se fija en los atributos entrenados (con _ al final)\n","        X = check_array(X)\n","        assert self.n_features_in_ == X.shape[1]\n","        if self.with_mean:\n","            X = X - self.mean_\n","        return X / self.scale_"]},{"cell_type":"markdown","metadata":{"id":"pcYiciKuDdWC"},"source":["## Pipelines\n","\n","### Implementemos un pipeline para procesar los datos numéricos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_-oh9vlHDdWD"},"outputs":[],"source":["from sklearn.pipeline import Pipeline\n","\n","num_pipeline = Pipeline([\n","    (\"impute\", SimpleImputer(strategy=\"median\")), # los nombres deben ser únicos y no tener __ (dobles guiones bajos)\n","    (\"standardize\", StandardScaler()),\n","])\n","num_pipeline"]},{"cell_type":"markdown","metadata":{"id":"w5FFnphiDdWD"},"source":["Los componentes deben ser transformers (tener el método `fit_transform()`) excepto el último que debe tener el método `fit()`.\n","\n","Cuando llamas al método `fit()` del pipeline, este llama secuencialmente a `fit_transform()` en todos los transformers, pasando la salida de cada llamada como parámetro a la siguiente llamada hasta llegar al estimador final, para el cual simplemente llama al método `fit()`.\n","\n","El pipeline expone los mismos métodos que el estimador final. En este ejemplo, el último estimador es un `StandardScaler`, que es un transformer, por lo que el pipeline también actúa como un transformer. Si llamamos al método `transform()` del pipeline, aplicará secuencialmente todas las transformaciones a los datos.\n","\n","Si el último estimador fuera un predictor en lugar de un transformador, entonces el pipeline tendrá un método `predict()` en lugar de `transform()`. Llamar a este método aplicaría secuencialmente todas las transformaciones a los datos y pasaría el resultado al método `predict()` del predictor."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5oeh1TYEDdWD"},"outputs":[],"source":["housing_num = housing.drop(\"ocean_proximity\", axis=1)\n","\n","housing_num_prepared = num_pipeline.fit_transform(housing_num)\n","housing_num_prepared[:2].round(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"li4iJa1yDdWE"},"outputs":[],"source":["num_pipeline.get_feature_names_out()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gepHFq5jDdWE"},"outputs":[],"source":["df_housing_num_prepared = pd.DataFrame(\n","    housing_num_prepared, columns=num_pipeline.get_feature_names_out(),\n","    index=housing_num.index)\n","df_housing_num_prepared"]},{"cell_type":"markdown","metadata":{"id":"ibnqfJVYDdWE"},"source":["### Mejor implementar un transformer que aplique las transformaciones necesarias a columnas numéricas y categóricas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Z8lNoxaDdWE"},"outputs":[],"source":["from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import make_pipeline\n","\n","num_attribs = [\"longitude\", \"latitude\", \"housing_median_age\", \"total_rooms\",\n","               \"total_bedrooms\", \"population\", \"households\", \"median_income\"]\n","cat_attribs = [\"ocean_proximity\"]\n","\n","num_pipeline = Pipeline([\n","    (\"impute\", SimpleImputer(strategy=\"median\")),\n","    (\"standardize\", StandardScaler()),\n","])\n","\n","cat_pipeline = make_pipeline(\n","    SimpleImputer(strategy=\"most_frequent\"),\n","    OneHotEncoder(handle_unknown=\"ignore\"))\n","\n","preprocessing = ColumnTransformer([\n","    (\"num\", num_pipeline, num_attribs),\n","    (\"cat\", cat_pipeline, cat_attribs),\n","])"]},{"cell_type":"markdown","metadata":{"id":"-2w7_1ddDdWE"},"source":["Otra forma de escribir el transformer anterior sin listar todos los nombres de las columnas y sin nombrar los transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B4mD-CZGDdWE"},"outputs":[],"source":["from sklearn.pipeline import make_pipeline\n","from sklearn.compose import make_column_selector, make_column_transformer\n","\n","num_pipeline = Pipeline([\n","    (\"impute\", SimpleImputer(strategy=\"median\")),\n","    (\"standardize\", StandardScaler()),\n","])\n","\n","cat_pipeline = make_pipeline(\n","    SimpleImputer(strategy=\"most_frequent\"),\n","    OneHotEncoder(handle_unknown=\"ignore\"))\n","\n","preprocessing = make_column_transformer(\n","    (num_pipeline, make_column_selector(dtype_include=np.number)),\n","    (cat_pipeline, make_column_selector(dtype_include=object)),\n",")"]},{"cell_type":"markdown","metadata":{"id":"X_gw5pdnDdWF"},"source":["Ahora si, apliquemos nuestro transformer!!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"isg836EWDdWF"},"outputs":[],"source":["housing_prepared = preprocessing.fit_transform(housing)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"twNHglGPDdWF"},"outputs":[],"source":["housing_prepared_df = pd.DataFrame(\n","    housing_prepared,\n","    columns=preprocessing.get_feature_names_out(),\n","    index=housing.index)\n","\n","housing_prepared_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3CfcvdF6DdWF"},"outputs":[],"source":["housing_prepared_df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QfDc379eDdWF"},"outputs":[],"source":["from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import make_pipeline\n","from sklearn.compose import make_column_selector\n","\n","num_pipeline = Pipeline([\n","    (\"impute\", SimpleImputer(strategy=\"median\")),\n","    (\"standardize\", StandardScaler()),\n","])\n","\n","cat_pipeline = make_pipeline(\n","    SimpleImputer(strategy=\"most_frequent\"),\n","    OneHotEncoder(handle_unknown=\"ignore\"))\n","\n","\n","log_pipeline = make_pipeline(\n","    SimpleImputer(strategy=\"median\"),\n","    FunctionTransformer(np.log, feature_names_out=\"one-to-one\"),\n","    StandardScaler())\n","\n","\n","preprocessing_2 = ColumnTransformer(\n","    [\n","        (\"log\", log_pipeline, [\"total_bedrooms\", \"total_rooms\", \"population\",\n","                               \"households\", \"median_income\"]),\n","        (\"cat\", cat_pipeline, make_column_selector(dtype_include=object)),\n","    ],\n","    remainder=num_pipeline\n","\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wyjvrZEqDdWF"},"outputs":[],"source":["housing_prepared_2 = preprocessing_2.fit_transform(housing)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CZ_eCf31DdWF"},"outputs":[],"source":["housing_prepared_df_2 = pd.DataFrame(\n","    housing_prepared_2,\n","    columns=preprocessing_2.get_feature_names_out(),\n","    index=housing.index)\n","\n","housing_prepared_df_2.head()"]},{"cell_type":"code","source":["housing_prepared_df_2[['log__population']].hist(bins=50)\n","\n","plt.show()"],"metadata":{"id":"6Sw6S9GG90dd"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"orig_nbformat":4,"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}