{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V28","authorship_tag":"ABX9TyM2zqpkr+SLVGy7i9Gg6cEh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VGfORq6ZN9cQ","executionInfo":{"status":"ok","timestamp":1715609385696,"user_tz":180,"elapsed":28774,"user":{"displayName":"Diana Carolina VERTIZ DEL VALLE","userId":"04236681262725283456"}},"outputId":"bc63f59d-53c5-4a74-ae0c-dd38ae31a663"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gymnasium\n","  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.25.2)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.11.0)\n","Collecting farama-notifications>=0.0.1 (from gymnasium)\n","  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n","Installing collected packages: farama-notifications, gymnasium\n","Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1\n"]}],"source":["!pip install gymnasium"]},{"cell_type":"code","source":["import gymnasium as gym\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from matplotlib.animation import FuncAnimation"],"metadata":{"id":"eQnGRUcqOK3F","executionInfo":{"status":"ok","timestamp":1715609386846,"user_tz":180,"elapsed":1153,"user":{"displayName":"Diana Carolina VERTIZ DEL VALLE","userId":"04236681262725283456"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["Frozen Lake es un entorno simple compuesto por casillas, donde el agente debe moverse desde una casilla inicial hasta una meta.\n","\n","Las casillas pueden ser un lago congelado seguro ‚úÖ o un agujero ‚ùå que te deja atrapado por siempre.\n","\n","El agente, tiene 4 acciones posibles: ir ‚óÄÔ∏èIZQUIERDA, üîΩABAJO, ‚ñ∂Ô∏èDERECHA o üîºARRIBA.\n","\n","El agente debe aprender a evitar los agujeros para poder alcanzar la meta en el menor n√∫mero de acciones posible.\n","\n","Por defecto, el entorno siempre tiene la misma configuraci√≥n. En el c√≥digo del entorno, cada casilla est√° representada por una letra de la siguiente manera:"],"metadata":{"id":"5PtJFZsxObHQ"}},{"cell_type":"code","source":["# S F F F       (S: inicio, seguro)\n","# F H F H       (F: superficie congelada, seguro)\n","# F F F H       (H: agujero, atrapado por siempre)\n","# H F F G       (G: meta, a salvo)"],"metadata":{"id":"6Q4YK5CTPGZi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["De hecho, es muy f√°cil encontrar varias soluciones correctas: DERECHA ‚Üí DERECHA ‚Üí ABAJO ‚Üí ABAJO ‚Üí ABAJO ‚Üí DERECHA es una obvia.\n","\n","Pero podr√≠amos hacer una secuencia de acciones que rodee un agujero 10 veces antes de llegar a la meta. Esta secuencia es v√°lida, pero no cumple con nuestro requisito final: el agente necesita alcanzar la meta en el menor n√∫mero de acciones posible.\n","\n","En este ejemplo, el n√∫mero m√≠nimo de acciones para completar el juego es 6. Necesitamos recordar este hecho para comprobar si nuestro agente realmente domina Frozen Lake o no."],"metadata":{"id":"dRlV0hD0O1Kr"}},{"cell_type":"code","source":["environment = gym.make(\"FrozenLake-v1\", is_slippery=False, render_mode=\"rgb_array\")\n","environment.reset()\n","environment.render()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"5loEIfuTOOAc","executionInfo":{"status":"ok","timestamp":1715609401310,"user_tz":180,"elapsed":526,"user":{"displayName":"Diana Carolina VERTIZ DEL VALLE","userId":"04236681262725283456"}},"outputId":"68fb8e6f-627c-46fa-8027-7b94bb6f7bac"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[180, 200, 230],\n","        [180, 200, 230],\n","        [180, 200, 230],\n","        ...,\n","        [180, 200, 230],\n","        [180, 200, 230],\n","        [180, 200, 230]],\n","\n","       [[180, 200, 230],\n","        [204, 230, 255],\n","        [204, 230, 255],\n","        ...,\n","        [204, 230, 255],\n","        [204, 230, 255],\n","        [180, 200, 230]],\n","\n","       [[180, 200, 230],\n","        [235, 245, 249],\n","        [204, 230, 255],\n","        ...,\n","        [204, 230, 255],\n","        [204, 230, 255],\n","        [180, 200, 230]],\n","\n","       ...,\n","\n","       [[180, 200, 230],\n","        [235, 245, 249],\n","        [235, 245, 249],\n","        ...,\n","        [204, 230, 255],\n","        [235, 245, 249],\n","        [180, 200, 230]],\n","\n","       [[180, 200, 230],\n","        [235, 245, 249],\n","        [235, 245, 249],\n","        ...,\n","        [204, 230, 255],\n","        [204, 230, 255],\n","        [180, 200, 230]],\n","\n","       [[180, 200, 230],\n","        [180, 200, 230],\n","        [180, 200, 230],\n","        ...,\n","        [180, 200, 230],\n","        [180, 200, 230],\n","        [180, 200, 230]]], dtype=uint8)"],"text/html":["<style>\n","      .ndarray_repr .ndarray_raw_data {\n","        display: none;\n","      }\n","      .ndarray_repr.show_array .ndarray_raw_data {\n","        display: block;\n","      }\n","      .ndarray_repr.show_array .ndarray_image_preview {\n","        display: none;\n","      }\n","      </style>\n","      <div id=\"id-f8211e24-839e-4424-9c33-f9c856fd5c4f\" class=\"ndarray_repr\"><pre>ndarray (256, 256, 3) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,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\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[[180, 200, 230],\n","        [180, 200, 230],\n","        [180, 200, 230],\n","        ...,\n","        [180, 200, 230],\n","        [180, 200, 230],\n","        [180, 200, 230]],\n","\n","       [[180, 200, 230],\n","        [204, 230, 255],\n","        [204, 230, 255],\n","        ...,\n","        [204, 230, 255],\n","        [204, 230, 255],\n","        [180, 200, 230]],\n","\n","       [[180, 200, 230],\n","        [235, 245, 249],\n","        [204, 230, 255],\n","        ...,\n","        [204, 230, 255],\n","        [204, 230, 255],\n","        [180, 200, 230]],\n","\n","       ...,\n","\n","       [[180, 200, 230],\n","        [235, 245, 249],\n","        [235, 245, 249],\n","        ...,\n","        [204, 230, 255],\n","        [235, 245, 249],\n","        [180, 200, 230]],\n","\n","       [[180, 200, 230],\n","        [235, 245, 249],\n","        [235, 245, 249],\n","        ...,\n","        [204, 230, 255],\n","        [204, 230, 255],\n","        [180, 200, 230]],\n","\n","       [[180, 200, 230],\n","        [180, 200, 230],\n","        [180, 200, 230],\n","        ...,\n","        [180, 200, 230],\n","        [180, 200, 230],\n","        [180, 200, 230]]], dtype=uint8)</pre></div><script>\n","      (() => {\n","      const titles = ['show data', 'hide data'];\n","      let index = 0\n","      document.querySelector('#id-f8211e24-839e-4424-9c33-f9c856fd5c4f button').onclick = (e) => {\n","        document.querySelector('#id-f8211e24-839e-4424-9c33-f9c856fd5c4f').classList.toggle('show_array');\n","        index = (++index) % 2;\n","        document.querySelector('#id-f8211e24-839e-4424-9c33-f9c856fd5c4f button').textContent = titles[index];\n","        e.preventDefault();\n","        e.stopPropagation();\n","      }\n","      })();\n","    </script>"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["En Frozen Lake, hay 16 casillas, lo que significa que nuestro agente puede encontrarse en 16 posiciones diferentes o estados.\n","\n","Para cada estado, hay 4 acciones posibles: ir ‚óÄÔ∏èIZQUIERDA, üîΩABAJO, ‚ñ∂Ô∏èDERECHA, y üîºARRIBA.\n","\n","El agente debe aprender qu√© acci√≥n elegir en cada estado. Para saber qu√© acci√≥n es la mejor en un estado dado, vamos a calcular el Valor-Q de cada acci√≥n (Recordar que este valor es funci√≥n del estado y la acci√≥n).\n","\n","Tenemos 16 estados y 4 acciones, por lo que queremos calcular 16 x 4 = 64 valores Q."],"metadata":{"id":"jDHzy5q3REkK"}},{"cell_type":"markdown","source":["Una forma pr√°ctica de representarlo es mediante una tabla, conocida como tabla Q, donde las filas enumeran cada estado s y las columnas enumeran cada acci√≥n a.\n","\n","En esta tabla Q, cada celda contiene el valor $Q(s, a)$, que son las recompensas esperadas de tomar la acci√≥n $a$ en el estado $s$\n","\n","Cuando nuestro agente se encuentra en un estado particular $s$, solo tiene que consultar esta tabla para ver qu√© acci√≥n tiene el valor m√°s alto."],"metadata":{"id":"ODx4VoV2RW-a"}},{"cell_type":"markdown","source":["``\n","S     ‚óÄÔ∏èLEFT    üîΩDOWN    ‚ñ∂Ô∏èRIGHT   üîºUP \\\n","0     Q(0,‚óÄÔ∏è)   Q(0,üîΩ)   Q(0,‚ñ∂Ô∏è)   Q(0,üîº) \\\n","1     Q(1,‚óÄÔ∏è)   Q(1,üîΩ)   Q(1,‚ñ∂Ô∏è)   Q(1,üîº) \\\n","2     Q(2,‚óÄÔ∏è)   Q(2,üîΩ)   Q(2,‚ñ∂Ô∏è)   Q(2,üîº) \\\n",". \\\n","14    Q(14,‚óÄÔ∏è)  Q(14,üîΩ)  Q(14,‚ñ∂Ô∏è)  Q(14,üîº) \\\n","G     Q(15,‚óÄÔ∏è)  Q(15,üîΩ)  Q(15,‚ñ∂Ô∏è)  Q(15,üîº)\n","``\n"],"metadata":{"id":"I8e82ltMScc_"}},{"cell_type":"code","source":["# Creamos la tabla y la inicializamos con ceros\n","# dimensi√≥n (filas x columnas) = (s x a) = 16 x 4\n","\n","nb_states = environment.observation_space.n  # = 16\n","nb_actions = environment.action_space.n      # = 4\n","qtable = np.zeros((nb_states, nb_actions))\n","\n","print('Q-table =')\n","print(qtable)"],"metadata":{"id":"zFrrdi1dRVNH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["``\n","‚óÄÔ∏è LEFT = 0 \\\n","üîΩ DOWN = 1 \\\n","‚ñ∂Ô∏è RIGHT = 2 \\\n","üîº UP = 3\n","``"],"metadata":{"id":"UdTqKkgST7e-"}},{"cell_type":"code","source":["# Para tomar una acci√≥n al azar\n","print(environment.reset())\n","\n","accion = environment.action_space.sample()\n","new_state, reward, done, info, p = environment.step(accion) # Retorna done=True si el agente cae a un agujero o llega a la meta\n","\n","accion2 = environment.action_space.sample()\n","new_state, reward, done, info, p = environment.step(accion2) # Retorna done=True si el agente cae a un agujero o llega a la meta\n","\n","print(accion)\n","print(f'recompensa:', reward)\n","print(f'Done:', done)\n","environment.render()"],"metadata":{"id":"71tjf_CET5k7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["La recompensa es 0 y solo un estado puede darnos una recompensa positiva en todo el juego. Si queremos ver una recompensa de 1, el agente debe tener la suerte suficiente para encontrar la secuencia correcta de acciones. La tabla Q permanecer√° llena de ceros hasta que el agente alcance aleatoriamente la meta."],"metadata":{"id":"U7r0PUxZWTzu"}},{"cell_type":"markdown","source":["Sabemos que obtenemos una recompensa de 1 cuando llegamos a la meta G. El valor-Q del estado junto a G (G-1) con la acci√≥n relevante para llegar a G se actualiza gracias a la recompensa. Se termina el episodio: el agente gan√≥ y se reinicia el juego. Ahora, la pr√≥xima vez que el agente est√© en un estado junto a G-1, aumentar√° el valor-Q del estado (llam√©moslo G-2) con la acci√≥n relevante para llegar a G-1. La pr√≥xima vez que el agente est√© en un estado junto a G-2, har√° lo mismo. se reinicia y repite, hasta que la actualizaci√≥n alcance el estado inicial S."],"metadata":{"id":"_haMRmsiYpOk"}},{"cell_type":"markdown","source":["Implementar el algoritmo Q-Learning para actualizar los valores-Q de la tabla-Q, recordar la ecuaci√≥n de actualizaci√≥n:\n","\n","$$\n","Q_{new}(s_t,a_t) =  Q(s_t,a_t) + \\eta\\cdot(r_t + \\gamma\\cdot\\max_a Q(s_{t+1}, a) - Q(s_t,a_t))\n","$$"],"metadata":{"id":"WazgAou9ac-J"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","def Q_learning(env, n_episodes, eta=0.5, gamma=0.9):\n","\n","    n_states = env.observation_space.n  # = 16\n","    n_actions = env.action_space.n      # = 4\n","    qtable = np.zeros((n_states, n_actions))\n","\n","    for _ in range(n_episodes):\n","        #reiniciar el agente\n","\n","        done = False\n","        #mientras no se finalice el episodio\n","        while not done:\n","            #selecciono una acci√≥n a partir del qtable para el estado actual\n","            #si son todos ceros, selecciono una acci√≥n al azar\n","\n","\n","            #implemento la acci√≥n usando step\n","\n","\n","            #actualizo los valores de qtable\n","\n","\n","            #actualizo el estado\n","            state = new_state\n","\n","    return qtable"],"metadata":{"id":"KAsS6tbuacqb","executionInfo":{"status":"ok","timestamp":1715609415881,"user_tz":180,"elapsed":3,"user":{"displayName":"Diana Carolina VERTIZ DEL VALLE","userId":"04236681262725283456"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["environment = gym.make(\"FrozenLake-v1\", is_slippery=False, render_mode=\"rgb_array\")\n","\n","Qt = Q_learning(environment, n_episodes=1000, eta=0.5, gamma=0.9)\n","Qt"],"metadata":{"id":"f4Gvuh1RZnG0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A continuaci√≥n implemente la pol√≠tica que retorne la acci√≥n del agente usando la Tabla-Q aprendida"],"metadata":{"id":"LTb2EL4YTBTW"}},{"cell_type":"code","source":["def basic_policy(env, Q_table, state):\n","    \"\"\"Pol√≠tica del agente\"\"\"\n","    if np.max(Q_table[state]) > 0:\n","        return np.argmax(Q_table[state])\n","    else:\n","        return env.action_space.sample()"],"metadata":{"id":"nsIXMnsv_ROy","executionInfo":{"status":"ok","timestamp":1715609435901,"user_tz":180,"elapsed":246,"user":{"displayName":"Diana Carolina VERTIZ DEL VALLE","userId":"04236681262725283456"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Funciones para animaci√≥n\n","def animate(num, patch, frames):\n","    patch.set_data(frames[num])\n","    return patch,\n","\n","def plot_animation(frames, repeat=False, interval=40):\n","    fig = plt.figure()\n","    patch = plt.imshow(frames[0])\n","    plt.axis('off')\n","    plt.close()\n","    anim = FuncAnimation(\n","        fig, animate, fargs=(patch, frames),\n","        frames=len(frames), repeat=repeat, interval=interval)\n","    return anim\n","\n","def show_one_episode(policy, Q_table):\n","    sequence = []\n","    frames = []\n","    env = gym.make(\"FrozenLake-v1\", is_slippery=False, render_mode=\"rgb_array\")\n","    state, info = env.reset()\n","    frames.append(env.render())\n","    done = False\n","    while not done:\n","        action = policy(env, Q_table, state)\n","        sequence.append(action)\n","        new_state, reward, done, info, p = env.step(action)\n","        frames.append(env.render())\n","        state = new_state\n","    print(frames[0].shape)\n","    return plot_animation(frames)"],"metadata":{"id":"GGYXMSaL-Ta_","executionInfo":{"status":"ok","timestamp":1715609431791,"user_tz":180,"elapsed":263,"user":{"displayName":"Diana Carolina VERTIZ DEL VALLE","userId":"04236681262725283456"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["from matplotlib import animation, rc\n","from IPython.display import HTML\n","\n","anim = show_one_episode(policy=basic_policy, Q_table=Qt)\n","rc('animation', html='jshtml')\n","anim"],"metadata":{"id":"IvY0SSM9GSRV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Hay algo a tener en cuenta con el enfoque anterior: el agente siempre elige la acci√≥n con el valor m√°s alto. Entonces, cada vez que un par estado-acci√≥n comienza a tener un valor distinto de cero, el agente siempre lo elegir√°. Las otras acciones nunca se tomar√°n, lo que significa que nunca actualizaremos su valor ¬øqu√© pasa si una de estas acciones es mejor que la que el agente siempre elige? ¬øNo deber√≠amos animar al agente a probar cosas nuevas de vez en cuando y ver si puede mejorar?"],"metadata":{"id":"D0koxWD5SbPk"}},{"cell_type":"markdown","source":["Entonces, queremos permitir que nuestro agente:\n","\n","1. Tome la acci√≥n con el valor m√°s alto (explotaci√≥n).\n","2. Elija una acci√≥n al azar para intentar encontrar incluso mejores acciones (exploraci√≥n).\n","\n","Es importante encontrar un equilibrio entre estos dos comportamientos: si el agente se enfoca solo en la explotaci√≥n, no puede probar nuevas soluciones y, por lo tanto, deja de aprender. Por otro lado, si el agente solo toma acciones al azar, el entrenamiento es in√∫til ya que no utiliza la tabla Q.\n","\n","Entonces, queremos cambiar este par√°metro con el tiempo: al principio del entrenamiento, queremos explorar el entorno tanto como sea posible. Pero la exploraci√≥n se vuelve menos interesante a medida que el agente ya conoce todos los pares estado-acci√≥n posibles. Este par√°metro representa la cantidad de aleatoriedad en la selecci√≥n de acciones.\n","\n","Esta t√©cnica se conoce com√∫nmente como el algoritmo epsilon-greedy, donde epsilon es nuestro par√°metro. Es un m√©todo simple pero extremadamente eficiente para encontrar un buen equilibrio. Cada vez que el agente tiene que tomar una acci√≥n, tiene una probabilidad Œµ de elegir una al azar, y una probabilidad 1-Œµ de elegir la que tiene el valor m√°s alto. Podemos disminuir el valor de epsilon al final de cada episodio en una cantidad fija (decaimiento lineal)."],"metadata":{"id":"TmF466c0Ydk9"}},{"cell_type":"code","source":["def epsilon_greedy(env, n_episodes, eta=0.5, gamma=0.9, epsilon=1, decay=0.001):\n","\n","    n_states = env.observation_space.n  # = 16\n","    n_actions = env.action_space.n      # = 4\n","    qtable = np.zeros((n_states, n_actions))\n","\n","    for _ in range(n_episodes):\n","        #reiniciar el agente\n","        state, _ = env.reset()\n","        done = False\n","        #mientras no se finalice el episodio\n","        while not done:\n","            # genero un n√∫mero aleatorio entre 0 y 1\n","\n","\n","            # si el n√∫mero es menor a epsilon\n","            # tomo una acci√≥n aleatorio\n","            # sino uso la qtable\n","\n","\n","\n","            #implemento la acci√≥n usando step\n","\n","\n","            #actualizo los valores de qtable\n","\n","\n","            #actualizo el estado\n","            state = new_state\n","\n","        #actualizo epsilon restando el decaimiento\n","\n","\n","    return qtable"],"metadata":{"id":"civQMGfhNbIM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["env2 = gym.make(\"FrozenLake-v1\", is_slippery=False, render_mode=\"rgb_array\")\n","\n","Qt = epsilon_greedy(env2, n_episodes=10000, eta=0.2, gamma=0.9)\n","Qt"],"metadata":{"id":"-juLIDoUTzzv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from matplotlib import animation, rc\n","from IPython.display import HTML\n","\n","anim = show_one_episode(policy=basic_policy, Q_table=Qt)\n","rc('animation', html='jshtml')\n","anim"],"metadata":{"id":"_m24ghN3aAtf"},"execution_count":null,"outputs":[]}]}