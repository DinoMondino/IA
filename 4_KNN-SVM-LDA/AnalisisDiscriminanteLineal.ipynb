{"cells":[{"cell_type":"markdown","id":"fd05e65b-801b-4220-a1c8-ae0c1243aea5","metadata":{"id":"fd05e65b-801b-4220-a1c8-ae0c1243aea5"},"source":["# **Análisis Discriminante lineal**\n","\n","El objetivo del Análisis Discriminante lineal (LDA) es encontrar el subespacio de características que optimiza la separabilidad de las clases y es una técnica supervisada.\n","El LDA como se conoce actualmente para múltiples clases, funciona bajo la suposición de que las clases tienen matrices de covarianza iguales y las clases tienen distribuciones normales. Otra suposición es que las instancias en el conjunto de entrenamiento son independientes entre si. Si una o más de una de las suposiciones anteriores no se cumplieran, la técnica del LDA funciona bastante bien."]},{"cell_type":"markdown","id":"x_JAHjINddIW","metadata":{"id":"x_JAHjINddIW"},"source":["## Pasos en el análisis discriminante lineal\n","\n"]},{"cell_type":"markdown","id":"SGcL6SAroHF-","metadata":{"id":"SGcL6SAroHF-"},"source":["Sea un conjunto de datos $\\mathbf{X}$ de dimensiones $n\\times d$ de $d$ características y n instancias:"]},{"cell_type":"markdown","id":"GYkNlpZ4dtfm","metadata":{"id":"GYkNlpZ4dtfm"},"source":["\n","\n","1.   Normalizar los datos $d$-dimensionales.\n","2.   Calcular los vectores de medias $\\mathbf{m}_i$ para cada clase.\n","$$\\mathbf{m}_i=\\frac{1}{n_i}\\sum_{\\mathbf{x}\\in D_i} \\mathbf{x}_m$$\n","3.   Calcular las matrices: matriz de dispersión entre clases $\\mathbf{S}_B$ y matriz de dispersión intra clase $\\mathbf{S}_W$.\n","4.   Calcular los autovectores y sus correspondientes autovalores de la matriz $\\mathbf{S}^{-1}_W \\mathbf{S}_B$.\n","5.   Ordenar los autovectores en orden decreciente a los autovalores y Seleccionar $k$ autovectores que correspondan a los $k$ autovalores más grandes.\n","6.   Formar una matriz $\\mathbf{W}$ de dimensiones $d \\times k$ donde cada columna representa un autovector.\n","7.   Proyectar las muestras en el nuevo subespacio de características usando la matriz de transformación para obtener los datos transformados en dimensión $n \\times k$.\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"FNYXIq_1dXYb","metadata":{"id":"FNYXIq_1dXYb"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"id":"S3hpcgvxElL_","metadata":{"id":"S3hpcgvxElL_"},"outputs":[],"source":["import sys\n","from IPython.display import Image, display\n","if 'google.colab' in sys.modules:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    %cd '/content/drive/MyDrive/Inteligencia Artificial/IA - Clases de Práctica/ContenidosPorTemas'"]},{"cell_type":"markdown","id":"IttjRTTSpUf_","metadata":{"id":"IttjRTTSpUf_"},"source":["Vamos a utilizar un dataset disponible de vinos (Wine dataset) que consiste en 178 instancias de 13 características que describen sus propiedades químicas. Las instancias pertenecen a una de 3 clases: 1,2,3 que hacen referencia a 3 tipos uvas cultivadas en una misma región de Italia pero derivadas de diferentes viñedos."]},{"cell_type":"code","execution_count":null,"id":"Gz7vGnSHri13","metadata":{"id":"Gz7vGnSHri13"},"outputs":[],"source":["df_wine = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data', header=None)\n","df_wine"]},{"cell_type":"markdown","id":"WTfnAgu6sRHW","metadata":{"id":"WTfnAgu6sRHW"},"source":["Extrae del dataset la columna correspondiente a las clases (columna 0) para formar el vector **y** y los datos **X** correspondientes a las características"]},{"cell_type":"code","execution_count":null,"id":"9691d0c6-a5f0-4a3f-b82e-aa49972a3639","metadata":{"id":"9691d0c6-a5f0-4a3f-b82e-aa49972a3639"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"wiFECXrxs_tc","metadata":{"id":"wiFECXrxs_tc"},"source":["Divide los datos en conjuntos de entrenamiento `X_train` y `y_train` y conjuntos de prueba `X_test` y `y_test` utiliza `random_state=42`"]},{"cell_type":"code","execution_count":null,"id":"Pbmw-rxTz57s","metadata":{"id":"Pbmw-rxTz57s"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n"]},{"cell_type":"markdown","id":"UzGch2Dds0Cu","metadata":{"id":"UzGch2Dds0Cu"},"source":["1. Normaliza los datos (d=13) para obtener las variables escaladas `X_train_std` y `X_test_std`."]},{"cell_type":"code","execution_count":null,"id":"cVMBbBGJs6Hz","metadata":{"id":"cVMBbBGJs6Hz"},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n"]},{"cell_type":"markdown","id":"Jrvba16uOeLs","metadata":{"id":"Jrvba16uOeLs"},"source":["2. Calcular los vectores de medias $\\mathbf{m}_i$ para cada clase.\n","$$\\mathbf{m}_i= \\left[ \\begin{align} &\\mu_0^{i} \\\\ &\\mu_1^{i} \\\\ &\\:\\vdots \\\\ &\\mu_{11}^{i} \\end{align} \\right] , \\quad i=1,2,3$$\n","\n","Guardar los 3 vectores en una lista llamada `mean_vecs`"]},{"cell_type":"code","execution_count":null,"id":"hcGatfl1PZFV","metadata":{"id":"hcGatfl1PZFV"},"outputs":[],"source":["np.set_printoptions(precision = 4)\n","\n"]},{"cell_type":"markdown","id":"BbU3RjLdUrJr","metadata":{"id":"BbU3RjLdUrJr"},"source":["3. Cálculo de las matrices:\n","\n","**Matriz intra-clase:**\n","\n","$\\mathbf{S}_W = \\sum \\mathbf{S_i}$\n","\n","Matriz de dispersión por clase:\n","\n","$\\mathbf{S}_i = \\sum_{\\mathbf{x}\\in D_i}(\\mathbf{x} - \\mathbf{m}_i)(\\mathbf{x}- \\mathbf{m}_i)^T$\n","\n","donde $D_i$ es el conjunto de intancias correspondiente a la clase $i$"]},{"cell_type":"code","execution_count":null,"id":"uEciFDDjOdzK","metadata":{"id":"uEciFDDjOdzK"},"outputs":[],"source":["d = 13\n","S_W = np.zeros((d, d))\n","for label, mv in zip(range(1, 4), mean_vecs):\n","    class_scatter = np.zeros((d, d))  # matriz de dispersión de cada clase\n","    for row in X_train_std[y_train == label]:\n","        row, mv = row.reshape(d, 1), mv.reshape(d, 1)  # vectores columna\n","        class_scatter += (row - mv).dot((row - mv).T)\n","    S_W += class_scatter                          # suma de las matrices de dispersión\n","\n","print('Matriz de dispersión intra-clase: '\n","      f'{S_W.shape[0]}x{S_W.shape[1]}')"]},{"cell_type":"markdown","id":"ihdd9gI3VCa6","metadata":{"id":"ihdd9gI3VCa6"},"source":["**Matriz entre-clases:**\n","\n","$\\mathbf{S}_B = \\sum_{i=1}^{c}n_i(\\mathbf{m}_i - \\mathbf{m})(\\mathbf{m}_i- \\mathbf{m})^T$\n","\n","Donde $\\mathbf{m}$ es el vector de medias global considerando todas las clases."]},{"cell_type":"code","execution_count":null,"id":"Pxjolg17XwQ5","metadata":{"id":"Pxjolg17XwQ5"},"outputs":[],"source":["mean_overall = np.mean(X_train_std, axis=0)\n","mean_overall = mean_overall.reshape(d, 1)  # lo hago vector columna\n","\n","d = 13  # number of features\n","S_B = np.zeros((d, d))\n","\n","for i, mean_vec in enumerate(mean_vecs):\n","    n = X_train_std[y_train == i + 1, :].shape[0]\n","    mean_vec = mean_vec.reshape(d, 1)\n","    S_B += n * (mean_vec - mean_overall).dot((mean_vec - mean_overall).T)\n","\n","print('Matriz de dispersión entre clases: '\n","      f'{S_B.shape[0]}x{S_B.shape[1]}')"]},{"cell_type":"markdown","id":"1dIoJDT4Ycfu","metadata":{"id":"1dIoJDT4Ycfu"},"source":["4.   Calcule los autovectores y sus correspondientes autovalores de la matriz $\\mathbf{S}^{-1}_W \\mathbf{S}_B$."]},{"cell_type":"code","execution_count":null,"id":"sAoPqOvoYdQz","metadata":{"id":"sAoPqOvoYdQz"},"outputs":[],"source":["eigen_vals, eigen_vecs = np.linalg.eig(np.linalg.inv(S_W).dot(S_B))"]},{"cell_type":"markdown","id":"DrkjYVfNYqUg","metadata":{"id":"DrkjYVfNYqUg"},"source":["5.   Ordene los autovectores en orden decreciente a los autovalores y Seleccione $k$ autovectores de acuerdo a los $k$ autovalores más grandes"]},{"cell_type":"markdown","id":"epQBrOaIY1DS","metadata":{"id":"epQBrOaIY1DS"},"source":["**Ordene los autovectores en orden descendente de los autovalores:**"]},{"cell_type":"code","execution_count":null,"id":"Og2q4tgHY6t3","metadata":{"id":"Og2q4tgHY6t3"},"outputs":[],"source":["# lista de tuplas (autovalor, autovector)\n","eigen_pairs = [ (np.abs(eigen_vals[i]), eigen_vecs[:, i].real) for i in range(len(eigen_vals))]\n","\n","# ordenamos las tuplas de mayor a menor\n","eigen_pairs = sorted(eigen_pairs, key=lambda k: k[0], reverse=True)\n","print('Autovalores en orden descendente:\\n')\n","for eigen_val in eigen_pairs:\n","    print(eigen_val[0])"]},{"cell_type":"markdown","id":"FWnpfQWGZkOE","metadata":{"id":"FWnpfQWGZkOE"},"source":["6.   Forme la matriz $\\mathbf{W}$ de dimensiones $d \\times k$ donde cada columna representa un autovector."]},{"cell_type":"code","execution_count":null,"id":"FM3BU-ePZoqT","metadata":{"id":"FM3BU-ePZoqT"},"outputs":[],"source":["w = np.hstack( (eigen_pairs[0][1].reshape(13,1), eigen_pairs[1][1].reshape(13,1)) )\n","print('Matriz W:\\n', w)"]},{"cell_type":"markdown","id":"SkL2b8yZnYCc","metadata":{"id":"SkL2b8yZnYCc"},"source":["7.   Proyecte las muestras en el nuevo subespacio de características usando la matriz de transformación para obtener los datos transformados en dimensión $n \\times k$."]},{"cell_type":"code","execution_count":null,"id":"iuEaRzttnbxs","metadata":{"id":"iuEaRzttnbxs"},"outputs":[],"source":["X_train_lda = X_train_std.dot(w)"]},{"cell_type":"markdown","id":"FzxeFWUNndBO","metadata":{"id":"FzxeFWUNndBO"},"source":["Realice un **gráfico de dispersión** de los datos tranformados `X_train_lda` en 2 dimensiones, utilice diferentes marcadores ('o', 's' ,'^') y diferentes colores para las 3 clases. Considera que las clases son separables en este subespacio?"]},{"cell_type":"code","execution_count":null,"id":"s-ndWWpyoUMw","metadata":{"id":"s-ndWWpyoUMw"},"outputs":[],"source":["colors = ['r', 'b', 'g']\n","markers = ['o', 's', '^']\n","\n"]},{"cell_type":"markdown","id":"ipz7NiDIoiMT","metadata":{"id":"ipz7NiDIoiMT"},"source":["## LDA usando Scikit-Learn\n","\n","Usando la [documentación](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html), utilice el análisis discriminante lineal de scikit learn sobre `X_train_std`para obtener el mismo resultado. Compare los graficos de dispersión."]},{"cell_type":"code","execution_count":null,"id":"QGAcmRUNohgQ","metadata":{"id":"QGAcmRUNohgQ"},"outputs":[],"source":["from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n","\n","#Entrenamiento"]},{"cell_type":"code","execution_count":null,"id":"7nBClYcHu6O6","metadata":{"id":"7nBClYcHu6O6"},"outputs":[],"source":["#Grafico los datos transformados (gráfico de dispersión)"]},{"cell_type":"markdown","id":"BorrXWSowtrd","metadata":{"id":"BorrXWSowtrd"},"source":["Evalue el modelo con los datos de prueba `X_test_std` y calcule el `accuracy`"]},{"cell_type":"code","source":[],"metadata":{"id":"3LpC7go-2nsb"},"id":"3LpC7go-2nsb","execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":5}