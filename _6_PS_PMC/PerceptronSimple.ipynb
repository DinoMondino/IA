{"cells":[{"cell_type":"code","execution_count":null,"id":"079d7e6f","metadata":{"id":"079d7e6f"},"outputs":[],"source":["import sys\n","\n","from IPython.display import Image, display\n","if 'google.colab' in sys.modules:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","\n","%cd '/content/drive/MyDrive/Inteligencia Artificial/IA - Clases de Práctica/ContenidosPorTemas'"]},{"cell_type":"markdown","id":"7512bc91","metadata":{"id":"7512bc91"},"source":["# Perceptrón Simple\n"]},{"cell_type":"markdown","id":"be5fa769-040c-4c53-83f0-a785db60e6c9","metadata":{"id":"be5fa769-040c-4c53-83f0-a785db60e6c9","tags":[]},"source":["Un Perceptrón simple (PS) es la red neuronal más sencilla que se puede considerar, está conformado por una sola neurona que posee N entradas y una función de transferencia de tipo umbral, tal como se ve en la siguiente figura:"]},{"cell_type":"code","execution_count":null,"id":"9918f6eb","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":349},"executionInfo":{"elapsed":1808,"status":"ok","timestamp":1713267435247,"user":{"displayName":"Diana Carolina VERTIZ DEL VALLE","userId":"04236681262725283456"},"user_tz":180},"id":"9918f6eb","outputId":"3259bff2-2602-4f07-e84e-2b786d926dbd"},"outputs":[],"source":["display(Image(filename='./2_imagenes/perceptron.png', width=1000))"]},{"cell_type":"markdown","id":"2189b931-5911-469d-a686-d7e194c8eddb","metadata":{"id":"2189b931-5911-469d-a686-d7e194c8eddb","tags":[]},"source":["Haciendo un pequeño cambio y llevando el umbral $\\theta$ hacia la izquierda en las ecuaciones anteriores, podemos definir un nuevo peso\n","$w_0$ y la entrada $x_0 = 1$ para poder escribir la salida de forma más compacta:"]},{"cell_type":"code","execution_count":null,"id":"j_z3_hPyI2pd","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":420},"executionInfo":{"elapsed":583,"status":"ok","timestamp":1713267435823,"user":{"displayName":"Diana Carolina VERTIZ DEL VALLE","userId":"04236681262725283456"},"user_tz":180},"id":"j_z3_hPyI2pd","outputId":"95f8a3d1-d6ae-45d0-9c80-a183e5fdf1ee"},"outputs":[],"source":["display(Image(filename='./2_imagenes/perceptron_bias.png', width=1000))"]},{"cell_type":"markdown","id":"1baeb641-fb5d-47d7-9a11-e984e0cf4a35","metadata":{"id":"1baeb641-fb5d-47d7-9a11-e984e0cf4a35","tags":[]},"source":["Podemos representar la salida con la siguiente expresión: $$y = sign(\\sum\\limits_{i=0}^N {x_i w_i})$$\n","\n","_**sign**_ corresponde a la función signo y es la _función de activación_ del perceptrón simple. Más adelante veremos que existen otras funciones de activación para otras aplicaciones."]},{"cell_type":"markdown","id":"99ccbde2-e77f-4c62-9abf-b7dededc4724","metadata":{"id":"99ccbde2-e77f-4c62-9abf-b7dededc4724"},"source":["El PS permite resolver problemas linealmente separables mediante una recta o un hiperplano de separación con ordenada al origen distinta de cero gracias al término de _Bias_"]},{"cell_type":"code","execution_count":null,"id":"zvffPPrQJHdw","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":361},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1713267435248,"user":{"displayName":"Diana Carolina VERTIZ DEL VALLE","userId":"04236681262725283456"},"user_tz":180},"id":"zvffPPrQJHdw","outputId":"f5f19d1d-6c68-40e3-839c-78dad9e45838"},"outputs":[],"source":["display(Image(filename='./2_imagenes/lineal_separable.png', width=700))"]},{"cell_type":"markdown","id":"69e50340-67d0-4c50-813b-45b9d1c1cbd0","metadata":{"id":"69e50340-67d0-4c50-813b-45b9d1c1cbd0"},"source":["A continuación, vamos a implementar la _clase Perceptron_ y el algoritmo de entrenamiento o _Regla del Perceptrón Simple_ 🙂\n","\n","Esta regla puede implementarse siguiendo estos pasos:\n","1. Inicializar el vector de pesos w con valores aleatorios entre 0 y 1.\n","2. Presentar un patrón de entrada x y calcular la salida $$y = sign(x_0 w_0 + \\sum\\limits_{i=1}^N {x_i w_i})$$  Recordemos que $w_0$ es el término correspondiente al bias y $x_0=1$, podemos representar la suma de productos usando un producto punto entre vectores: $$y = sign( w_0 + \\vec{w}^T \\cdot \\vec{x})$$\n","\n","3. Calcular el error entre la salida obtenida y la salida deseada $y_d$ $$e = y - y_d$$\n","4. Ajustar los pesos de la red con la siguiente ecuación: $$ \\vec{w} = \\vec{w} + \\mu \\vec{e} \\cdot \\vec{x}$$ $\\mu$ es el coeficiente de aprendizaje o factor de entrenamiento (eta)\n","5. Volver al paso 2 y repetir el proceso hasta terminar el número de iteraciones"]},{"cell_type":"code","execution_count":null,"id":"df9236c0","metadata":{"id":"df9236c0"},"outputs":[],"source":["# Librerías a importar\n","import numpy as np\n","from numpy.random import RandomState\n","import matplotlib.pyplot as plt\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"id":"8a2436fd","metadata":{"id":"8a2436fd"},"outputs":[],"source":["class Perceptron(object):\n","    \"\"\"Perceptrón simple.\n","\n","    Parámetros\n","    ------------\n","    eta : float\n","        factor de entrenamiento (entre 0.0 y 1.0)\n","    epocas : int\n","        iteraciones para el entrenamiento.\n","    random_state : int\n","        Semilla generadora de números aleatorios para la inicialización de los pesos.\n","\n","    Atributos\n","    -----------\n","    w_ : 1d-array\n","        Pesos despues del entrenamiento.\n","    mal_clasificados_ : list\n","        Número de desaciertos en cada época\n","    \"\"\"\n","    def __init__(self, eta=0.001, epocas=1, random_state=None):\n","        self.eta = eta\n","        self.epocas = epocas\n","        self.random_state = random_state\n","\n","    def fit(self, X, y):\n","        \"\"\"Función de entrenamiento.\n","        Parameters\n","        ----------\n","        X : array, shape = [n_muestras, n_caracteristicas]\n","          vector de entrenamiento\n","        y : array, shape = [n_muestras]\n","          vector target.\n","\n","        Returns\n","        -------\n","        self : objeto\n","\n","        \"\"\"\n","\n","        rgen = RandomState(self.random_state)\n","        #inicializo los pesos con valores aleatorios entre 0 y 1 rgen.normal\n","        # https://numpy.org/doc/stable/reference/random/generated/numpy.random.RandomState.normal.html\n","\n","        self.w_ = np.zeros(1 + X.shape[1])\n","        self.mal_clasificados_ = []\n","        self.errores_ = []\n","    \n","        # para cada época\n","        for _ in range(self.epocas):\n","            errores = 0\n","\n","            for xi, target in zip(X, y):\n","\n","                # cálculo de la salida\n","                nuevo = self.eta * (target - self.predict(xi))\n","\n","                # cálculo del error y actualización del vector de pesos\n","                self.w_[1:] += nuevo * xi\n","                self.w_[0] += nuevo\n","                if nuevo != 0.0:\n","                    errores += 1\n","                    self.mal_clasificados_.append((xi, target))\n","            self.errores_.append(errores)\n","\n","        return self\n","\n","    def calcular_entrada(self, x):\n","        \"\"\"cálculo de la entrada al perceptrón\"\"\"\n","        # -------suma de los productos de los valores de entrada y los pesos -----------\n","        suma = sum([i * w for i, w in zip(x, self.w_)])\n","        return suma\n","        #-------------------------------------------------------------------------------\n","\n","    def predict(self, X):\n","        \"\"\"devuelve la etiqueta de la clase pertenciente después de aplicar la fn. de activación\"\"\"\n","        # la función de activación es la función signo:\n","        # 0 si el resultado de calcular_entrada < 0\n","        # 1 si el resultado de calcular_entrada >= 0\n","\n","        if self.calcular_entrada(X) < 0:\n","            return 0 \n","        else:\n","            return 1\n","        "]},{"cell_type":"markdown","id":"0f02a46c-4251-4780-a422-8b5ba173f71d","metadata":{"id":"0f02a46c-4251-4780-a422-8b5ba173f71d"},"source":["## Dataset Iris\n","El conjunto de datos flor Iris contiene 50 muestras de cada una de tres especies de Iris (Iris setosa, Iris versicolor e Iris virginica), en total 150 muestras. Se tienen 4 características: el largo y ancho del sépalo y pétalo, en centímetros."]},{"cell_type":"code","execution_count":null,"id":"28151f66","metadata":{"id":"28151f66"},"outputs":[],"source":["df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header=None)\n","\n","df.tail()"]},{"cell_type":"markdown","id":"031c6744-b0f1-421c-884e-0f98b108dfdc","metadata":{"id":"031c6744-b0f1-421c-884e-0f98b108dfdc"},"source":["# Graficamos el Dataset"]},{"cell_type":"markdown","id":"TRO8wEIg28ak","metadata":{"id":"TRO8wEIg28ak"},"source":["Separe los datos en predictores (`X`) y etiquetas (`y`). Considere sólo las clases `setosa`y `versicolor` y los atributos de la primer y tercera columnas como características de entrada, Largo de sépalo (primer columna) y largo de pétalo (tercer columna). Grafique los datos."]},{"cell_type":"code","execution_count":null,"id":"037aef30","metadata":{"id":"037aef30"},"outputs":[],"source":["#convertimos las etiquetas de clases en  0 (Iris-setosa)  y 1 (Iris-versicolor)\n","\n","X = df.iloc[:, :-1]\n","y = df.iloc[:, -1].copy()\n","\n","for x in range(len(y)):\n","    if y[x] == \"Iris-setosa\":\n","        y[x] = 0\n","    elif y[x] == \"Iris-versicolor\":\n","        y[x] = 1\n","    else:\n","        y[x] = 7 \n","\n","y = y.astype(int)\n","\n","X = X.iloc[:, [0, 2]].values\n","\n","y\n"]},{"cell_type":"code","execution_count":null,"id":"AoqecmvkE3ON","metadata":{"id":"AoqecmvkE3ON"},"outputs":[],"source":["plt.scatter(X[y == 0][:, 0], X[y == 0][:, 1], color='red', label='y=0')\n","plt.scatter(X[y == 1][:, 0], X[y == 1][:, 1], color='blue', label='y=1')\n","\n","plt.xlabel('Largo del sepalo')\n","plt.ylabel('Largo del petalo')\n","plt.title('Datos')\n","plt.legend()\n","\n","plt.show()"]},{"cell_type":"markdown","id":"f0a8b099-f254-40df-9843-68a859c4e2b2","metadata":{"id":"f0a8b099-f254-40df-9843-68a859c4e2b2"},"source":["# Entrenamiento del Perceptrón\n","\n","Utilice la clase implementada para entrenar el perceptrón, pruebe con diferentes valores de coeficiente de entrenamiento y número de iteraciones.\n","\n","Haga un gráfico de los mal clasificados por época en función de las épocas y una gráfica de los errores de entrenamiento en cada iteración."]},{"cell_type":"code","execution_count":null,"id":"c795c4f9","metadata":{"id":"c795c4f9"},"outputs":[],"source":["#Instancio un objeto de la clase Perceptron\n","perceptron = Perceptron()\n","\n","#llamo al método fit\n","perceptron.fit(X, y)"]},{"cell_type":"code","execution_count":null,"id":"22f24d3e","metadata":{},"outputs":[],"source":["#Grafico el número de errores o mal clasificados en cada iteración\n","\n","plt.plot(perceptron.errores_, marker='o')\n","plt.xlabel('Iteracion')\n","plt.ylabel('Numero de Errores')\n","plt.title('Errores por Iteracion')\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"9fe2f7f0","metadata":{},"outputs":[],"source":["#Grafico el número de errores por época"]},{"cell_type":"markdown","id":"02969f89-9b89-44d0-b15c-c1e258662bf6","metadata":{"id":"02969f89-9b89-44d0-b15c-c1e258662bf6"},"source":["Recordemos la ecuación: $$y = sign(w_0 + \\sum\\limits_{i=1}^N {x_i w_i})$$\n","\n","Para este problema con dos características (x1 = longitudes del sépalo y x2= longitudes de pétalo ), la ecuación resulta:\n","\n","$$y = sign(x_1 w_1 + x_2 w_2 + w_0)$$\n","\n","Donde se separan las dos clases de flores, tendremos la frontera de decisión, dada por la ecuación:\n","\n","$$x_1 w_1 + x_2 w_2 + w_0 = 0$$\n","\n","De esta ecuación podemos despejar la recta $x_2$ en función de $x_1$ que separa las clases en el espacio de soluciones\n","\n","$$x_2 + x_1 \\frac{w_1}{w_2} + \\frac{w_0}{w_2} = 0$$\n","\n","$$x_2 =  -\\frac{w_1}{w_2}x_1 - \\frac{w_0}{w_2} $$\n","\n","La pendiente de la recta  $ m = -\\frac{w_1}{w_2}$ y la ordenada al origen $ b = - \\frac{w_0}{w_2}$"]},{"cell_type":"markdown","id":"2f1e7402-6c3e-48d6-aac0-36b01009a147","metadata":{"id":"2f1e7402-6c3e-48d6-aac0-36b01009a147"},"source":["### Ahora vamos a graficar esta recta"]},{"cell_type":"code","execution_count":null,"id":"a5a34485-59c2-4a9a-8aed-66fc872c9928","metadata":{"id":"a5a34485-59c2-4a9a-8aed-66fc872c9928"},"outputs":[],"source":["#------------------ Representación de la recta ------------------------------------\n","# vector de pesos del perceptrón entrenado\n","pesos = perceptron.w_\n","# cálculo de la pendiente\n","pendiente = -(pesos[1]/pesos[2])\n","# cálculo de la ordenada al origen\n","ordenada = -(pesos[0]/pesos[2])\n","# armo la recta y la grafico junto a los datos\n","\n","pesos\n"]},{"cell_type":"markdown","id":"twQ0BQeA2wRZ","metadata":{"id":"twQ0BQeA2wRZ"},"source":["## Perceptrón Usando scikit-learn\n","\n","Ahora utilice las 3 clases del conjunto de datos usando las mismas características (atributos de la primer y tercera columnas). separe los datos en entrenamiento y prueba (20% datos de prueba), `random_state=100`"]},{"cell_type":"code","execution_count":null,"id":"o0SJwJsW91cT","metadata":{"id":"o0SJwJsW91cT"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","X = df.iloc[:, :-1]\n","y = df.iloc[:, -1].copy()\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)"]},{"cell_type":"markdown","id":"uePDuapTkV9d","metadata":{"id":"uePDuapTkV9d"},"source":["Entrene un perceptrón simple usando la clase [Perceptron](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html) de scikit-learn."]},{"cell_type":"code","execution_count":null,"id":"N-kcnzJF1EEj","metadata":{"id":"N-kcnzJF1EEj"},"outputs":[],"source":["from sklearn.linear_model import Perceptron\n","\n","percep = Perceptron()\n","percep.fit(X_train, y_train)"]},{"cell_type":"markdown","id":"2punbqXwkpWW","metadata":{"id":"2punbqXwkpWW"},"source":["Utilice la función plot_decision_regions para graficar las regiones de decisión de las 3 clases, grafique los datos de entrenamiento y prueba, diferenciándolos"]},{"cell_type":"code","execution_count":null,"id":"82e5bf89","metadata":{},"outputs":[],"source":["# pip install mlxtend"]},{"cell_type":"code","execution_count":null,"id":"20427f83","metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from mlxtend.plotting import plot_decision_regions"]},{"cell_type":"code","execution_count":null,"id":"355a7ff6","metadata":{},"outputs":[],"source":["X_train_np = X_train.values\n","y_train_np = y_train.values\n","X_test_np = X_test.values\n","y_test_np = y_test.values\n","y_train_np = np.array(y_train)\n","y_test_np = np.array(y_test)"]},{"cell_type":"code","execution_count":null,"id":"28456588-1c71-47ce-b23f-f58c96207140","metadata":{"id":"28456588-1c71-47ce-b23f-f58c96207140"},"outputs":[],"source":["plot_decision_regions(X_train_np, y_train_np, clf=percep)\n","plt.title('Perceptron - Training Data')\n","plt.xlabel('feature 1')\n","plt.ylabel('feature 2')\n","plt.show()\n","\n","plot_decision_regions(X_test_np, y_test_np, clf=percep)\n","plt.title('Perceptron - Test Data')\n","plt.xlabel('feature 1')\n","plt.ylabel('feature 2')\n","plt.show()"]},{"cell_type":"markdown","id":"pFoRaMtgFtGQ","metadata":{"id":"pFoRaMtgFtGQ"},"source":["Evalúe el desempeño del clasificador"]},{"cell_type":"code","execution_count":null,"id":"LAtSBomn1D0s","metadata":{"id":"LAtSBomn1D0s"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":5}
